{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk import sent_tokenize\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "пора скачать книженьку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences_raw.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "просто невозможно читать \\n на \\n, почищу\n",
    "просто разбиением, без выделения сокращений ничего нормально точно не разобъется, \n",
    "я уберу мистеров (пыталась учитывать их регуляркой, но не вышло)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters. “My dear problem_1 Bennet,” said his lady to him one day, “have you heard that Netherfield Park is let at last?” problem_1 Bennet replied that he had not. “But it is,” returned she; “for problem_1. Long has just been here, and she told me all about it.” problem_1 Bennet made no answer. “Do you not want to know who has taken it?” cried his wife impatiently. “You want to tell me, and I have no objection to hearing it.” This was invitation enough. “Why, my dear, you must know, problem_1. Long says that Netherfield is taken by a young man of large fortune from the north of England; that he came down on Monday in a chaise'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = re.sub('\\s+', ' ', data)\n",
    "data = re.sub('Mr.', 'problem_1', data) #потом можно обратно заменить, потому что без этого все летит\n",
    "data = re.sub('Mrs.', 'problem_2', data)\n",
    "data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = '.*?[.?!][ ”]+'\n",
    "d = re.findall(regex, data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "подготовим ручной текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences.txt', 'r', encoding='utf-8') as f:\n",
    "    test = f.read()\n",
    "test = re.sub('\\n+', '\\n', test)\n",
    "test = re.sub('Mr.', 'problem_1', test) #потом можно обратно заменить, потому что без этого все летит\n",
    "test = re.sub('Mrs.', 'problem_2', test)\n",
    "t = test.split('\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "***\n",
    "Если говорить про \n",
    "regex = '[.?!] [A-Z]'\n",
    "re.split(regex, data)[:5]\n",
    "То у меня он жрет заглавную букву, так что по любой метрике неправильно все. \n",
    "Плюс, опять же, кавычки он за пробел не считает\n",
    "Плюс, с мистерами беда, но я решила их пока заменить на что-то вразумительное\n",
    "Вот\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences_raw.txt', 'r', encoding='utf-8') as f:\n",
    "    data1 = f.read()\n",
    "data1 = re.sub('\\s+', ' ', data1)\n",
    "regex1 = '.*?[.?!] '\n",
    "d1 = re.findall(regex1, data1)\n",
    "\n",
    "with open('sentences.txt', 'r', encoding='utf-8') as f:\n",
    "    test1 = f.read()\n",
    "test1 = re.sub('\\n+', '\\n', test1)\n",
    "t1 = test1.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Austen_Jane_Pride_and_Prejudice.txt', 'r', encoding='utf-8') as f:\n",
    "    data2 = f.read()\n",
    "data2 = re.sub('\\s+', ' ', data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PunktTrainer()\n",
    "trainer.INCLUDE_ALL_COLLOCS = True\n",
    "trainer.train(data2)\n",
    " \n",
    "tokenizer = PunktSentenceTokenizer(trainer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f', 'p', 'woe', '“m', 'vow', 'err', 'Mrs', 'etc', '“mrs', 'Mr', 'mr', 'mrs', 'st', 'w', 'cry', 'b', '‘mr', 'esq', '“e', '“mr'}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer._params.abbrev_types)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "кул, наверное, теперь отобъем по последнему предложению первой главы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = tokenizer.tokenize(data2)\n",
    "d2 = gold[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences.txt', 'r', encoding='utf-8') as f:\n",
    "    test2 = f.read()\n",
    "test2 = re.sub('\\n+', '\\n', test2)\n",
    "test2 = re.sub(' \\n', '\\n', test2)\n",
    "t2 = test2.split('\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "теперь вот есть три набора\n",
    "руками придуманный умный (d t)\n",
    "тупо как просили (d1 t1)\n",
    "токенайзер (d2 t2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "посчитаем: тупо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18811881188118812"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(d) & set(t)) / len(set(d) | set(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14606741573033707"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(d1) & set(t1)) / len(set(d1) | set(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21333333333333335"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(d2) & set(t2)) / len(set(d2) | set(t2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Почему все плохо? Токенайзеру плохо от кавычек. Ха-ха"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "на всякий случай посмотрю на какую-нибудь еще метрику, она ничего не даст, но пусть увидим, что токенайзер своей работоой доволен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.9935014869479017\n",
      "Recall -  0.9870868899102648\n",
      "F1 -  0.9902838008453643\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for sent in gold:\n",
    "    if len(sent_tokenize(sent)) == 1:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "\n",
    "for i in range(len(gold)-1):\n",
    "    sent1, sent2 = gold[i], gold[i+1]\n",
    "    sent = ' '.join([sent1, sent2])\n",
    "    if len(sent_tokenize(sent)) == 2:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "\n",
    "precision = (tp/(tp+fp))\n",
    "recall = (tp/(tp+fn))\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "print('Precision - ', precision)\n",
    "print('Recall - ', recall)\n",
    "print('F1 - ', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
